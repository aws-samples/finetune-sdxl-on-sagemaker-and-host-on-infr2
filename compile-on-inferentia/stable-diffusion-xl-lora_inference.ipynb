{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "931e6c30-f543-44b9-9b72-0c6a3ad4068a",
   "metadata": {},
   "source": [
    "# Stable Diffusion XL with Neuronx: LoRA adapters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5db370-a95c-4cc9-966d-0fe39e9c0731",
   "metadata": {},
   "source": [
    "`ðŸ¤— Optimum` extends `ðŸ¤— Diffusers` to support inference on the second generation of Neuron devices(powering Trainium and Inferentia 2). It aims at inheriting the ease of Diffusers on Neuron.\n",
    "\n",
    "Before you get started, make sure you have run the scripts install-drivers.sh and install-pytorch-neuron.sh, and the notebook is running on torch-neuronx kernel \n",
    "For more details, refer to [configured your inf2 / trn1 instance](https://huggingface.co/docs/optimum-neuron/installation)\n",
    "\n",
    "Lets start by installing optimum for easy inference and peft for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791a79d2-886e-4e0f-9e73-415c39ada834",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install \"optimum[neuronx, diffusers]\" \n",
    "pip install -U peft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd5283a-e1af-411b-b53b-0ad4bc6161c5",
   "metadata": {},
   "source": [
    "## Compilation\n",
    "\n",
    "To deploy SDXL models, we will also start by compiling the models. We support the export of following components in the pipeline to boost the speed:\n",
    "\n",
    "* Text encoder\n",
    "* Second text encoder\n",
    "* U-Net (a three times larger UNet than the one in Stable Diffusion pipeline)\n",
    "* VAE encoder\n",
    "* VAE decoder\n",
    "\n",
    "You can either compile and export a Stable Diffusion Checkpoint via CLI or `NeuronStableDiffusionXLPipeline` class. \n",
    "In this tutorial, we will export [`stabilityai/stable-diffusion-xl-base-1.0`](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0) with the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6cf331-dc03-433d-a41d-43b3d3866c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimum.neuron import NeuronStableDiffusionXLPipeline\n",
    "\n",
    "model_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "adapter_id = \"lora\"\n",
    "input_shapes = {\"batch_size\": 1, \"height\": 1024, \"width\": 1024, \"num_images_per_prompt\": 1}\n",
    "\n",
    "# Compile\n",
    "pipe = NeuronStableDiffusionXLPipeline.from_pretrained(\n",
    "    model_id,\n",
    "    export=True,\n",
    "    inline_weights_to_neff=True,  # caveat: performance drop if neff/weights separated, will be improved by a future Neuron sdk release.\n",
    "    lora_model_ids=adapter_id,\n",
    "    lora_weight_names=\"pytorch_lora_weights.safetensors\",\n",
    "    lora_adapter_names=\"sttirum\",\n",
    "    **input_shapes,\n",
    ")\n",
    "\n",
    "# Save locally or upload to the HuggingFace Hub\n",
    "save_directory = \"sd_neuron_xl/\"\n",
    "\n",
    "pipe.save_pretrained(save_directory) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd060668-4974-44f9-90c5-88ebc77fe2a9",
   "metadata": {},
   "source": [
    "\n",
    "We Recommend `inf2.8xlarge` or larger for compilation. You will also be able to compile the models with a CPU-only instance *(needs ~92GB memory)* using the CLI with `--disable-validation`, which disables the validation of inference on neuron devices.\n",
    "\n",
    "In the following section, we will run the pre-compiled model on Neuron devices, to reduce expenses, you can run inference with `inf2.xlarge` instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a23f38-3fdd-4c17-9804-0fbc464e1fe1",
   "metadata": {},
   "source": [
    "## Text-to-image Inference\n",
    "\n",
    "If you have pre-compiled Stable Diffusion XL models, you can load them directly to skip the compilation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b094483c-9a19-4295-b355-6e17d53100cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimum.neuron import NeuronStableDiffusionXLPipeline\n",
    "\n",
    "stable_diffusion_xl = NeuronStableDiffusionXLPipeline.from_pretrained(\"sd_neuron_xl\")  # Pass a local path or your repo id on the HuggingFace hub."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7d6dbb",
   "metadata": {},
   "source": [
    "Run the pipeline passing a prompt with the unique identifier that was used while fine-tuning the model initially\n",
    "Edit the Prompt below and generate multiple avatars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a850cc-9a55-4700-a45a-98d748151769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Run pipeline\n",
    "prompt = \"\"\"\n",
    "photo of <<TOK>> pencil sketch, young and beautiful, face front, centered\n",
    "\"\"\"         \n",
    "\n",
    "negative_prompt = \"\"\"\n",
    "ugly, tiling, poorly drawn hands, poorly drawn feet, poorly drawn face, out of frame, extra limbs, disfigured, deformed, body out of frame, blurry, bad anatomy, blurred, \n",
    "watermark, grainy, signature, cut off, draft, amateur, multiple, gross, weird, uneven, furnishing, decorating, decoration, furniture, text, poor, low, basic, worst, juvenile, \n",
    "unprofessional, failure, crayon, oil, label, thousand hands\n",
    "\"\"\"\n",
    "\n",
    "seed = 491057365\n",
    "generator = [torch.Generator().manual_seed(seed)]\n",
    "\n",
    "image = stable_diffusion_xl(prompt, \n",
    "             num_inference_steps=50, \n",
    "             guidance_scale=7, \n",
    "             negative_prompt=negative_prompt,\n",
    "             generator=generator).images[0]\n",
    "\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bcf496",
   "metadata": {},
   "source": [
    "## Clean-up\n",
    "\n",
    "After completion, stop the EC2 instance to save the costs. You can download the pretrained model in /sd_neuron_xl and load for inference later.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch-neuronx)",
   "language": "python",
   "name": "aws_neuron_venv_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
